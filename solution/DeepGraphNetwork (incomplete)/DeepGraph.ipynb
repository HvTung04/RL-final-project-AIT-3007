{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VI0i44SXb1dg"
      },
      "outputs": [],
      "source": [
        "from magent2.environments import battle_v4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9eGwUjECcIeh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aK7WT-qxb1di"
      },
      "outputs": [],
      "source": [
        "# Turn on minimap mode for agent's location\n",
        "env = battle_v4.env(map_size=45, render_mode='rgb_array', minimap_mode=True, max_cycles=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "70pyWvTub1dj"
      },
      "outputs": [],
      "source": [
        "# MLP for observation encoding\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, observation_shape=(13, 13, 9), feature_dim=128):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Calculate the flattened input size\n",
        "        self.input_dim = observation_shape[0] * observation_shape[1] * observation_shape[2]  # 13 * 13 * 9\n",
        "\n",
        "        # Define the network layers\n",
        "        self.layers = nn.Sequential(\n",
        "            # First flatten the input\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # First dense layer with 512 units\n",
        "            nn.Linear(self.input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second dense layer with feature_dim units (128 in original)\n",
        "            nn.Linear(512, feature_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Reshape layer to match original output shape (1, feature_dim)\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (13, 13, 9)\n",
        "        if len(x.shape) == 3:\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "        # x shape: (batch_size, 13, 13, 9)\n",
        "\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Pass through MLP layers\n",
        "        features = self.layers(x)\n",
        "\n",
        "        # Reshape to (batch_size, 1, feature_dim) to match original output shape\n",
        "        features = features.unsqueeze(1)\n",
        "\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jZUBo9EXb1dk"
      },
      "outputs": [],
      "source": [
        "def get_team_observations(env, handle):\n",
        "    \"\"\"\n",
        "    Get team observations from environment and convert to tensor.\n",
        "\n",
        "    Args:\n",
        "        env: Environment object\n",
        "        handle: Team handle (e.g. \"red\", \"blue\")\n",
        "\n",
        "    Returns:\n",
        "        observations: List of team observations size N x 13 x 13 x 9\"\"\"\n",
        "    observations = []\n",
        "    for agent in env.possible_agents:\n",
        "        if handle in agent:\n",
        "            if env.terminations.get(agent, True) or env.truncations.get(agent, True):\n",
        "                obs = np.zeros((13, 13, 9))\n",
        "            else:\n",
        "                obs = env.observe(agent)\n",
        "            observations.append(torch.tensor(obs, dtype=torch.float32))\n",
        "\n",
        "    return observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "etq2zngOb1dl"
      },
      "outputs": [],
      "source": [
        "def get_agent_positions(team_obs):\n",
        "    \"\"\"\n",
        "    Extract positions of all agents from team observations.\n",
        "\n",
        "    Args:\n",
        "        team_obs: List of team observations.\n",
        "                 Each obs shape is (13, 13, 9) where:\n",
        "                 - channels[-2:] are the agent's absolute position (x, y)\n",
        "\n",
        "    Returns:\n",
        "        Dict of agent positions {agent_idx: (x, y)}\n",
        "    \"\"\"\n",
        "    positions = {}\n",
        "\n",
        "    # For each agent in the team\n",
        "    for agent_idx, obs in enumerate(team_obs):\n",
        "        # Get absolute positions from last two channels\n",
        "        x_pos = obs[0, 0, -2]  # Second to last channel for x coordinate\n",
        "        y_pos = obs[0, 0, -1]  # Last channel for y coordinate\n",
        "\n",
        "        positions[agent_idx] = (x_pos, y_pos)\n",
        "\n",
        "    return positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gXDOlYQAb1dl"
      },
      "outputs": [],
      "source": [
        "def construct_adjacency_matrix(team_obs, n_neighbors=4):\n",
        "    \"\"\"\n",
        "    Construct adjacency matrix C^t_i for each agent i.\n",
        "\n",
        "    Args: Dict of team observations {agent_idx: obs}\n",
        "          n_neighbors: Number of neighbors to consider (default: 4)\n",
        "\n",
        "    Returns: List of adjacency matrices for each agent\n",
        "    \"\"\"\n",
        "    adjacency_matrices = []\n",
        "\n",
        "    # Get agent positions\n",
        "    positions = get_agent_positions(team_obs)\n",
        "    num_agents = 81\n",
        "\n",
        "    for i in positions.keys():\n",
        "        distances = []\n",
        "        for j in positions.keys():\n",
        "            if i != j:\n",
        "                # Calculate Euclidean distance between agent i and j (in normalized coordinates)\n",
        "                dist = ((positions[j][0] - positions[i][0]) ** 2 + (positions[j][1] - positions[i][1]) ** 2) ** 0.5\n",
        "                distances.append((dist, j))\n",
        "\n",
        "        distances.sort(key=lambda x: x[0])  # Sort by distance\n",
        "\n",
        "        adj_matrix = torch.zeros((n_neighbors + 1, num_agents))\n",
        "\n",
        "        adj_matrix[0, i] = 1  # Self-connection\n",
        "\n",
        "        for idx, (dist, neighbor_idx) in enumerate(distances[:n_neighbors]):\n",
        "            adj_matrix[idx + 1, neighbor_idx] = 1\n",
        "\n",
        "        while(len(distances) < n_neighbors + 1):\n",
        "            adj_matrix.append(torch.zeros((n_neighbors + 1, num_agents)))\n",
        "\n",
        "        adjacency_matrices.append(adj_matrix)\n",
        "\n",
        "    # Pad with zero matrices if needed\n",
        "    while len(adjacency_matrices) < num_agents:\n",
        "        adjacency_matrices.append(torch.zeros((n_neighbors + 1, num_agents)))\n",
        "\n",
        "    return adjacency_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4eBtS-cTb1dm"
      },
      "outputs": [],
      "source": [
        "def process_timestep(env, handle):\n",
        "    \"\"\"\n",
        "    Process one timestep for all agents.\n",
        "\n",
        "    Args:\n",
        "        env: Environment object\n",
        "        handle: Team handle (e.g. \"red\", \"blue\")\n",
        "\n",
        "    Returns:\n",
        "        observations: List of size N with each element as a tensor of shape (13, 13, 9)\n",
        "        adjacency_matrices: List of size N with each element as a tensor of shape (5, N)\n",
        "    \"\"\"\n",
        "    # Get team observations\n",
        "    observations = get_team_observations(env, handle)\n",
        "\n",
        "    # Get adjacency matrices for all agents\n",
        "    adjacency_matrices = construct_adjacency_matrix(observations)\n",
        "\n",
        "    return observations, adjacency_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GcFDfEyxb1dn"
      },
      "outputs": [],
      "source": [
        "# Multihead dot-product attention as the convolutional kernel => interaction between agents\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multihead attention module for DGN\n",
        "\n",
        "    Args:\n",
        "        n_neighbors: Number of neighbors to consider\n",
        "        input_dim: Input dimension of the feature vectors\n",
        "        head_dim: Dimension of each head\n",
        "        num_heads: Number of attention heads\n",
        "        output_dim: Output dimension of the feature vectors\n",
        "    \"\"\"\n",
        "    def __init__(self, n_neighbors, input_dim, head_dim, num_heads, output_dim):\n",
        "        super(MultiheadAttention, self).__init__()\n",
        "\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.input_dim = input_dim\n",
        "        self.head_dim = head_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # Linear transformation for Q, K, V\n",
        "        self.query_layer = nn.Linear(input_dim, head_dim * num_heads)\n",
        "        self.key_layer = nn.Linear(input_dim, head_dim * num_heads)\n",
        "        self.value_layer = nn.Linear(input_dim, head_dim * num_heads)\n",
        "\n",
        "        # Final transformation\n",
        "        self.output_layer = nn.Linear(head_dim * num_heads, output_dim)\n",
        "\n",
        "        # ReLU activation\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, query, value, key, extra_vector):\n",
        "        \"\"\"\n",
        "        Forward pass for multihead attention\n",
        "\n",
        "        Args:\n",
        "            query: Query tensor of shape (batch_size, n_neighbors + 1, L = input_dim)\n",
        "            value: Value tensor of shape (batch_size, n_neighbors + 1, L = input_dim)\n",
        "            key: Key tensor of shape (batch_size, n_neighbors + 1, L = input_dim)\n",
        "            extra_vector: Extra vector of shape (batch_size, 1, n_neighbors + 1)\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape (batch_size, 1, output_dim)\n",
        "        \"\"\"\n",
        "        if query.dim() == 2:\n",
        "            query = query.unsqueeze(0)\n",
        "            key = key.unsqueeze(0)\n",
        "            value = value.unsqueeze(0)\n",
        "            extra_vector = extra_vector.unsqueeze(0)\n",
        "\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear transformation with ReLU\n",
        "        query_2 = self.relu(self.query_layer(query)) # Shape (batch_size, n_neighbors + 1, head_dim * num_heads)\n",
        "        key_2 = self.relu(self.key_layer(key))  # Shape (batch_size, n_neighbors + 1, head_dim * num_heads)\n",
        "        value_2 = self.relu(self.value_layer(value))    # Shape (batch_size, n_neighbors + 1, head_dim * num_heads)\n",
        "\n",
        "        # Reshape to separate heads\n",
        "        # Shape (batch_size, n_neighbors + 1, num_heads, head_dim)\n",
        "        reshaped_query = query_2.view(batch_size, self.n_neighbors + 1, self.num_heads, self.head_dim)\n",
        "        reshaped_key = key_2.view(batch_size, self.n_neighbors + 1, self.num_heads, self.head_dim)\n",
        "        reshaped_value = value_2.view(batch_size, self.n_neighbors + 1, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Permute dimensions for attention\n",
        "        # Shape (batch_size, num_heads, n_neighbors + 1, head_dim)\n",
        "        final_query = reshaped_query.permute(0, 2, 1, 3)\n",
        "        final_key = reshaped_key.permute(0, 2, 1, 3)\n",
        "        final_value = reshaped_value.permute(0, 2, 1, 3)\n",
        "\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        attention_scores = torch.matmul(final_query, final_key.transpose(-2, -1)) / np.sqrt(self.head_dim)  # (batch_size, num_heads, n_neighbors + 1, n_neighbors + 1)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)  # (batch_size, num_heads, n_neighbors + 1, n_neighbors + 1)\n",
        "\n",
        "        # Apply attention to values\n",
        "        attention_output = torch.matmul(attention_weights, final_value)  # (batch_size, num_heads, n_neighbors + 1, head_dim)\n",
        "\n",
        "        # Permute back and reshape\n",
        "        attention_output = attention_output.permute(0, 2, 1, 3).contiguous()  # (batch_size, n_neighbors + 1, num_heads, head_dim)\n",
        "        attention_output = attention_output.view(batch_size, self.n_neighbors + 1, -1)  # (batch_size, n_neighbors + 1, num_heads * head_dim)\n",
        "\n",
        "        # Apply extra vector\n",
        "        output = torch.matmul(extra_vector, attention_output)  # (batch_size, 1, num_heads * head_dim)\n",
        "\n",
        "        # Final linear transformation\n",
        "        output = self.relu(self.output_layer(output))  # (batch_size, 1, output_dim)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rxOmpWpCb1dp"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, feature_dim=128, action_dim=21):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(feature_dim * 3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, action_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, feature, relation1, relation2):\n",
        "        combined = torch.cat([feature, relation1, relation2], dim=-1)\n",
        "        return self.network(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HIA1vbM72zWp"
      },
      "outputs": [],
      "source": [
        "def find_dead(env, handle):\n",
        "    \"\"\"\n",
        "    Find dead agents in the environment.\n",
        "\n",
        "    Args:\n",
        "        env: Environment object\n",
        "        handle: Team handle (e.g. \"red\", \"blue\")\n",
        "\n",
        "    Returns:\n",
        "        List of dead agents\n",
        "    \"\"\"\n",
        "    dead_agents = []\n",
        "    for agent in env.possible_agents:\n",
        "        if handle in agent:\n",
        "            if env.terminations.get(agent, True) or env.truncations.get(agent, True):\n",
        "                agent_id = int(agent.split('_')[1])\n",
        "                dead_agents.append(agent_id)\n",
        "    return dead_agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LFwjK20nb1dq"
      },
      "outputs": [],
      "source": [
        "class DGN(nn.Module):\n",
        "    def __init__(self, observation_shape=(13, 13, 9), feature_dim=128, action_dim=21):\n",
        "        super(DGN, self).__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "        self.mlp = MLP(observation_shape, feature_dim)\n",
        "\n",
        "        self.attention1 = MultiheadAttention(n_neighbors=4, input_dim=feature_dim, head_dim=16, num_heads=8, output_dim=feature_dim)\n",
        "        self.attention2 = MultiheadAttention(n_neighbors=4, input_dim=feature_dim, head_dim=16, num_heads=8, output_dim=feature_dim)\n",
        "\n",
        "        self.q_network = QNetwork(feature_dim, action_dim)\n",
        "\n",
        "        # Initialize extra_vector with batch dimension\n",
        "        self.extra_vector_template = nn.Parameter(torch.zeros(1, 1, 5))\n",
        "        nn.init.ones_(self.extra_vector_template)\n",
        "        self.extra_vector_template.data[0, 0, 0] = 1\n",
        "\n",
        "    def local_features(self, features, adjacency_matrices):\n",
        "        \"\"\"\n",
        "        Compute local features for all agents\n",
        "\n",
        "        Args:\n",
        "            features: Tensor of shape (batch_size, N, feature_dim)\n",
        "            adjacency_matrices: Tensor of shape (batch_size, n_neighbors + 1, N)\n",
        "\n",
        "        Returns:\n",
        "            local_features: Tensor of shape (batch_size, n_neighbors + 1, feature_dim)\n",
        "        \"\"\"\n",
        "        local_features = torch.matmul(adjacency_matrices, features)\n",
        "\n",
        "        return local_features\n",
        "\n",
        "    def forward(self, team_observations, adjacency_matrices):\n",
        "        \"\"\"\n",
        "        Forward pass for DGN\n",
        "\n",
        "        Args:\n",
        "            team_observations: List N Tensor of shape (batch_size, 13, 13, 9)\n",
        "            adjacency_matrices: List N Tensor of shape (batch_size, n_neighbors + 1, N)\n",
        "\n",
        "        Returns:\n",
        "            q_values: Q values of shape (batch_size, action_dim)\n",
        "        \"\"\"\n",
        "        n_agents = 81\n",
        "        if team_observations[0].dim() == 3:\n",
        "            team_observations = [obs.unsqueeze(0) for obs in team_observations]\n",
        "        batch_size = team_observations[0].size(0)\n",
        "        extra_vector = self.extra_vector_template.expand(batch_size, -1, -1)\n",
        "\n",
        "        # Etract features for all agents\n",
        "        team_features = torch.cat([self.mlp(obs) for obs in team_observations], dim=1)  # Shape (batch_size, N, feature_dim)\n",
        "\n",
        "        # First relation layer\n",
        "        local_features = [self.local_features(team_features, adjacency_matrix) for adjacency_matrix in adjacency_matrices]  # Shape (batch_size, n_neighbors + 1, feature_dim)\n",
        "        relation1 = {}\n",
        "        for i in range(n_agents):\n",
        "            query = key = value = local_features[i]\n",
        "            relation1[i] = self.attention1(query, value, key, extra_vector) # Shape (batch_size, 1, feature_dim)\n",
        "\n",
        "        # Second relation layer\n",
        "        relation2 = {}\n",
        "        for i in range(n_agents):\n",
        "            start_index = max(0, i - 4 // 2)\n",
        "            end_index = min(n_agents, start_index + 4)\n",
        "\n",
        "            start_index = max(0, end_index - 4)\n",
        "            neighbors = list(relation1.values())[start_index:end_index]\n",
        "            neighbors.append(relation1[i])\n",
        "            if len(neighbors) < 5:\n",
        "                for _ in range(5-len(neighbors)):\n",
        "                    neighbors.append(torch.zeros(relation1[i].shape))\n",
        "            neighbors = [neighbor.to(device) for neighbor in neighbors]\n",
        "\n",
        "            query = torch.cat(neighbors, dim=1).to(device)\n",
        "            key = torch.cat(neighbors, dim=1).to(device)\n",
        "            value = torch.cat(neighbors, dim=1).to(device)\n",
        "            # Process attention\n",
        "            rel2 = self.attention2(query, key, value, extra_vector)\n",
        "            relation2[i] = rel2 # Shape (batch_size, 1, feature_dim)\n",
        "\n",
        "        # Compute Q values\n",
        "        q_values = []\n",
        "        for i in range(n_agents):\n",
        "            agent_q = self.q_network(team_features[:, i, :].unsqueeze(1), relation1[i], relation2[i]) # Shape (batch_size, 1, action_dim)\n",
        "            q_values.append(agent_q)\n",
        "\n",
        "        # Stack Q values to create Q table\n",
        "        q_values = torch.cat(q_values, dim=1) # Shape (batch_size, N, action_dim)\n",
        "\n",
        "        return q_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JCE4fUtob1dr"
      },
      "outputs": [],
      "source": [
        "num_episodes = 30\n",
        "learning_rate = 0.001\n",
        "gamma = 0.95\n",
        "epsilon = 0.7\n",
        "epsilon_decay = 0.99\n",
        "target_update = 10\n",
        "max_steps = 300\n",
        "batch_size = 15\n",
        "handle = 'blue'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bHd6CtLMb1ds"
      },
      "outputs": [],
      "source": [
        "# Load pretrained agent\n",
        "from pretrained_agent import RED_DQN\n",
        "\n",
        "red_agent = RED_DQN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r2s2s4njb1ds"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy_action(agent_idx, q_values, epsilon):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(21)\n",
        "    else:\n",
        "        return q_values[:, agent_idx].argmax().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dOkF-viIb1ds"
      },
      "outputs": [],
      "source": [
        "def update_target_model(model, target_model):\n",
        "    target_model.load_state_dict(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0QUj6Gfb1dt",
        "outputId": "aeae8716-4970-45c8-ceab-17e026a07785"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DGN(\n",
              "  (mlp): MLP(\n",
              "    (layers): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=1521, out_features=512, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (4): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (attention1): MultiheadAttention(\n",
              "    (query_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (key_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (value_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (output_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (attention2): MultiheadAttention(\n",
              "    (query_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (key_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (value_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (output_layer): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (q_network): QNetwork(\n",
              "    (network): Sequential(\n",
              "      (0): Linear(in_features=384, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=21, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blue_team = DGN()\n",
        "blue_team_target = DGN()\n",
        "\n",
        "blue_team.to(device)\n",
        "blue_team_target.to(device)\n",
        "\n",
        "update_target_model(blue_team, blue_team_target)\n",
        "optimizer = torch.optim.Adam(blue_team.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "blue_team_target.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kfBUdVbGb1du"
      },
      "outputs": [],
      "source": [
        "from ReplayBuffer import ReplayBuffer\n",
        "\n",
        "replay_buffer = ReplayBuffer(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY2XGjYJb1du",
        "outputId": "4b004660-11dc-48f6-c352-f07f635fc772"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 1/30: 100%|█████████▉| 299/300 [05:25<00:01,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1/30, Total reward: -969.7950339373201, Epsilon: 0.693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 2/30: 100%|██████████| 300/300 [05:28<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 2/30, Total reward: -929.3900331715122, Epsilon: 0.68607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 3/30: 100%|██████████| 300/300 [05:45<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 3/30, Total reward: -934.0850342651829, Epsilon: 0.6792092999999999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 4/30: 100%|██████████| 300/300 [05:35<00:00,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 4/30, Total reward: -787.1900276495144, Epsilon: 0.6724172069999999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 5/30: 100%|█████████▉| 299/300 [05:34<00:01,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 5/30, Total reward: -805.2950272476301, Epsilon: 0.6656930349299999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 6/30: 100%|█████████▉| 299/300 [05:38<00:01,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 6/30, Total reward: -789.0950262686238, Epsilon: 0.6590361045806998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 7/30: 100%|██████████| 300/300 [05:34<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 7/30, Total reward: -786.3900270452723, Epsilon: 0.6524457435348928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 8/30: 100%|██████████| 300/300 [05:23<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 8/30, Total reward: -813.8850282831118, Epsilon: 0.6459212860995439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 9/30: 100%|██████████| 300/300 [05:11<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 9/30, Total reward: -733.5700266202912, Epsilon: 0.6394620732385484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 10/30: 100%|█████████▉| 299/300 [05:16<00:01,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 10/30, Total reward: -832.2950282981619, Epsilon: 0.6330674525061629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 11/30: 100%|██████████| 300/300 [05:13<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 11/30, Total reward: -808.5850283633918, Epsilon: 0.6267367779811013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 12/30: 100%|██████████| 300/300 [05:19<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 12/30, Total reward: -1102.690039953217, Epsilon: 0.6204694102012902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 13/30: 100%|█████████▉| 299/300 [05:30<00:01,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 13/30, Total reward: -830.2950280895457, Epsilon: 0.6142647160992774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 14/30: 100%|██████████| 300/300 [05:26<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 14/30, Total reward: -1157.9900421937928, Epsilon: 0.6081220689382846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 15/30: 100%|█████████▉| 299/300 [05:23<00:01,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 15/30, Total reward: -1059.0950379082933, Epsilon: 0.6020408482489017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 16/30: 100%|██████████| 300/300 [05:23<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 16/30, Total reward: -1002.1750373998657, Epsilon: 0.5960204397664127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 17/30: 100%|██████████| 300/300 [05:28<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 17/30, Total reward: -688.4750227006152, Epsilon: 0.5900602353687486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 18/30: 100%|█████████▉| 299/300 [05:28<00:01,  1.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 18/30, Total reward: -723.4950233353302, Epsilon: 0.5841596330150611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 19/30: 100%|██████████| 300/300 [05:13<00:00,  1.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 19/30, Total reward: -875.6800309345126, Epsilon: 0.5783180366849106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 20/30: 100%|█████████▉| 299/300 [05:34<00:01,  1.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 20/30, Total reward: -697.0950223887339, Epsilon: 0.5725348563180614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 21/30: 100%|█████████▉| 299/300 [05:44<00:01,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 21/30, Total reward: -655.0950205223635, Epsilon: 0.5668095077548808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 22/30: 100%|██████████| 300/300 [05:27<00:00,  1.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 22/30, Total reward: -701.8900228329003, Epsilon: 0.561141412677332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 23/30: 100%|██████████| 300/300 [05:45<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 23/30, Total reward: -611.0850207125768, Epsilon: 0.5555299985505586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 24/30: 100%|█████████▉| 299/300 [05:37<00:01,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 24/30, Total reward: -679.1950214877725, Epsilon: 0.549974698565053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 25/30: 100%|██████████| 300/300 [05:24<00:00,  1.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 25/30, Total reward: -529.3400206984952, Epsilon: 0.5444749515794024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 26/30: 100%|██████████| 300/300 [05:33<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 26/30, Total reward: -741.2950246185064, Epsilon: 0.5390302020636084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 27/30: 100%|██████████| 300/300 [05:46<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 27/30, Total reward: -682.2050223331898, Epsilon: 0.5336399000429723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 28/30: 100%|██████████| 300/300 [05:41<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 28/30, Total reward: -720.4250247180462, Epsilon: 0.5283035010425426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 29/30: 100%|██████████| 300/300 [05:51<00:00,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 29/30, Total reward: -727.5850235382095, Epsilon: 0.5230204660321172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Episode 30/30: 100%|██████████| 300/300 [05:28<00:00,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 30/30, Total reward: -639.3550214357674, Epsilon: 0.517790261371796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for episode in range(num_episodes):\n",
        "    env.reset()\n",
        "    # Get initial observations\n",
        "    team_observations, adj_matrices = process_timestep(env, handle)\n",
        "    episode_reward = 0\n",
        "\n",
        "    for step in tqdm(range(max_steps), desc=f\"Episode {episode+1}/{num_episodes}\"):\n",
        "        actions = [] # Store actions for blue agent\n",
        "        rewards = [] # Store rewards for blue agent\n",
        "\n",
        "        dones = [env.terminations.get(agent_id, True) or env.truncations.get(agent_id, True) for agent_id in [f\"{handle}_{i}\" for i in range(81)]]\n",
        "\n",
        "        team_observations = [obs.to(device) for obs in team_observations] # Move observations to GPU\n",
        "        adj_matrices = [adj_matrix.to(device) for adj_matrix in adj_matrices] # Move adj_matrices to GPU\n",
        "        q_values = blue_team(team_observations, adj_matrices)\n",
        "\n",
        "        dead_agents = find_dead(env, handle)\n",
        "\n",
        "        # Get actions for each agent\n",
        "        for agent in env.agent_iter():\n",
        "            end = agent == env.agents[-1]\n",
        "            observation, reward, terminated, truncated, _ = env.last()\n",
        "            if terminated or truncated:\n",
        "                action = None\n",
        "                if \"blue\" in agent:\n",
        "                    actions.append(0)\n",
        "                    rewards.append(-10)\n",
        "            elif \"red\" in agent:\n",
        "                obs = torch.Tensor(env.observe(agent))\n",
        "                action = red_agent.get_action(obs)\n",
        "            elif \"blue\" in agent:\n",
        "                # env.agent_selection = blue_0\n",
        "                agent_idx = int(agent.split('_')[1])\n",
        "                action = epsilon_greedy_action(agent_idx, q_values, epsilon)\n",
        "                actions.append(action)\n",
        "                rewards.append(reward)\n",
        "            env.step(action)\n",
        "\n",
        "            if end:\n",
        "                break\n",
        "\n",
        "        for dead_agent in dead_agents:\n",
        "            actions.insert(dead_agent, None)\n",
        "            rewards.insert(dead_agent, 0)\n",
        "        # Get next state\n",
        "        next_observations, next_adj_matrices = process_timestep(env, handle)\n",
        "\n",
        "        if len(team_observations) != len(next_observations) or len(actions) != len(next_observations) or len(dones) != len(next_observations):\n",
        "            continue\n",
        "        else:\n",
        "            replay_buffer.add(team_observations, actions, rewards, next_observations, torch.Tensor(dones), adj_matrices)\n",
        "\n",
        "        if replay_buffer.count() > batch_size:\n",
        "            observations_, actions_, rewards_, next_observations_, dones_, adj_matrices_ = replay_buffer.getBatch(batch_size)\n",
        "\n",
        "            observations_ = observations_.to(device)\n",
        "            actions_ = actions_.to(device)\n",
        "            rewards_ = rewards_.to(device)\n",
        "            next_observations_ = next_observations_.to(device)\n",
        "            dones_ = dones_.to(device)\n",
        "            adj_matrices_ = adj_matrices_.to(device)\n",
        "\n",
        "            # Compute target Q values\n",
        "            observations_ = list(observations_.unbind(0))\n",
        "            adj_matrices_ = list(adj_matrices_.unbind(0))\n",
        "            next_observations_ = list(next_observations_.unbind(0))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                target_values = rewards_.T + gamma * blue_team_target(observations_, adj_matrices_).max(dim=-1).values * (1 - dones_.T)\n",
        "            q_values_ = blue_team(next_observations_, adj_matrices_) # Shape (batch_size, N, action_dim)\n",
        "\n",
        "            actions_ = actions_.T # Shape (batch_size, N)\n",
        "\n",
        "            q_values_ = q_values_[torch.arange(batch_size).unsqueeze(1), torch.arange(81).unsqueeze(0), actions_] # Shape (batch_size, N)\n",
        "            # Compute loss\n",
        "            loss = criterion(q_values_, target_values)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Soft update target network\n",
        "            for target_param, param in zip(blue_team_target.parameters(), blue_team.parameters()):\n",
        "                target_param.data.copy_(0.99 * target_param.data + 0.01 * param.data)\n",
        "\n",
        "        # Update state\n",
        "        observations = next_observations\n",
        "        adj_matrices = next_adj_matrices\n",
        "        episode_reward += sum(rewards)\n",
        "        if all(dones) or all([env.terminations.get(agent_id, True) or env.truncations.get(agent_id, True) for agent_id in [f\"red_{i}\" for i in range(81)]]):\n",
        "            break\n",
        "\n",
        "    epsilon = max(0.1, epsilon * epsilon_decay)\n",
        "\n",
        "    # Logging\n",
        "\n",
        "    tqdm.write(f\"Episode {episode+1}/{num_episodes}, Total reward: {episode_reward}, Epsilon: {epsilon}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z-s1n8T2b1dw"
      },
      "outputs": [],
      "source": [
        "torch.save(blue_team.state_dict(), 'blue_team_model_V3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1691b249cc0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(env.render())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
