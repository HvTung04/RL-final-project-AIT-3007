{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.821503Z","iopub.status.busy":"2024-12-21T12:21:48.821240Z","iopub.status.idle":"2024-12-21T12:21:48.827415Z","shell.execute_reply":"2024-12-21T12:21:48.826493Z","shell.execute_reply.started":"2024-12-21T12:21:48.821482Z"},"trusted":true},"outputs":[],"source":["from magent2.environments import battle_v4\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.optim as optim\n","import random\n","from collections import deque\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tqdm\n","  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: colorama in c:\\users\\natsu\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n","Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n","Installing collected packages: tqdm\n","Successfully installed tqdm-4.67.1\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.829593Z","iopub.status.busy":"2024-12-21T12:21:48.829367Z","iopub.status.idle":"2024-12-21T12:21:48.872693Z","shell.execute_reply":"2024-12-21T12:21:48.872090Z","shell.execute_reply.started":"2024-12-21T12:21:48.829574Z"},"trusted":true},"outputs":[],"source":["env = battle_v4.parallel_env(map_size=45)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.874360Z","iopub.status.busy":"2024-12-21T12:21:48.874057Z","iopub.status.idle":"2024-12-21T12:21:48.878906Z","shell.execute_reply":"2024-12-21T12:21:48.878071Z","shell.execute_reply.started":"2024-12-21T12:21:48.874332Z"},"trusted":true},"outputs":[],"source":["config = {\n","    \"obs_shape\": env.observation_space(\"red_0\").shape,\n","    \"action_dims\": int(env.action_space(\"red_0\").n),\n","    \"buffer_alpha\": 0.6,\n","    \"beta\": 0.4,\n","    \"beta_increment\": 1e-3,\n","    \"learning_rate\": 0.0005,\n","    \"buffer_size\": 10000,\n","    \"epsilon\": 1.0,\n","    \"epsilon_decay\": 0.998,\n","    \"epsilon_min\": 0.05,\n","    \"gamma\": 0.98, # discount\n","    \"batch_size\": 218,\n","    \"tau\": 0.005, # soft update,\n","    \"red_update_interval\": 2,\n","    \"blue_update_interval\": 2,\n","    \"num_episode\": 50,\n","    \"num_step\": 1000,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.879957Z","iopub.status.busy":"2024-12-21T12:21:48.879668Z","iopub.status.idle":"2024-12-21T12:21:48.898263Z","shell.execute_reply":"2024-12-21T12:21:48.897449Z","shell.execute_reply.started":"2024-12-21T12:21:48.879924Z"},"trusted":true},"outputs":[],"source":["class QNetwork(nn.Module):\n","  def __init__(self, obs_shape, actions_dim, kernel_size=3, stride=1, padding=1):\n","      super(QNetwork, self).__init__()\n","\n","      self.conv1 = nn.Conv2d(\n","          obs_shape[-1],\n","          32,\n","          kernel_size=kernel_size,\n","          stride=stride,\n","          padding=padding\n","      ) # 5 channels -> 32 features map\n","      self.conv2 = nn.Conv2d(\n","          32,\n","          64,\n","          kernel_size=kernel_size,\n","          stride=stride,\n","          padding=padding\n","      ) # 32 channels -> 64 features map\n","\n","      self.fc1 = nn.Linear(\n","          64 * obs_shape[0] * obs_shape[1],\n","          128\n","      ) # Flat 64 * 13 * 13 -> 128 neurons\n","      self.fc2 = nn.Linear(\n","          128,\n","          actions_dim\n","      ) # 128 neurons -> 1 action\n","\n","  def forward(self, x):\n","      x = x.permute(0, 3, 1, 2) # (batch_size, width, height, channels) -> (batch_size, channels, width, height)\n","\n","      # Convolution with ReLU activation\n","      x = torch.relu(self.conv1(x))\n","      x = torch.relu(self.conv2(x))\n","\n","      x = x.reshape(x.size(0), -1) # (batch_size, flatten_size)\n","\n","      # Fully connected layers\n","      x = torch.relu(self.fc1(x))\n","      x = self.fc2(x)\n","      return x"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["test_input = torch.randn(1, *config[\"obs_shape\"])\n","test_model = QNetwork(config[\"obs_shape\"], config[\"action_dims\"])\n","test_output = test_model(test_input)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 21])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["test_output.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.899306Z","iopub.status.busy":"2024-12-21T12:21:48.899070Z","iopub.status.idle":"2024-12-21T12:21:48.913225Z","shell.execute_reply":"2024-12-21T12:21:48.912455Z","shell.execute_reply.started":"2024-12-21T12:21:48.899287Z"},"trusted":true},"outputs":[],"source":["class MixingNetwork(nn.Module):\n","    def __init__(self, num_agents, state_shape):\n","        super(MixingNetwork, self).__init__()\n","        self.conv1 = nn.Conv2d(state_shape[-1], 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(64 * state_shape[0] * state_shape[1], 128)\n","        self.fc2 = nn.Linear(128 + num_agents, 1)  # Combine state features with Q-values\n","\n","    def forward(self, q_values, state):\n","        # q_values: (batch_size, num_agents)\n","        # state: (batch_size, state_shape)\n","        state = state.permute(0, 3, 1, 2)  # (batch_size, channels, height, width)\n","        state = torch.relu(self.conv1(state))\n","        state = torch.relu(self.conv2(state))\n","        state = state.reshape(state.size(0), -1)  # Flatten\n","        state_features = torch.relu(self.fc1(state))\n","\n","        # Concatenate state features with Q-values\n","        combined = torch.cat((state_features, q_values), dim=1)\n","        return self.fc2(combined)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (1x129600 and 10816x128)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_q_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m81\u001b[39m,\u001b[38;5;241m21\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m81\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_mixing_model \u001b[38;5;241m=\u001b[39m MixingNetwork(\u001b[38;5;241m81\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m test_output_mix \u001b[38;5;241m=\u001b[39m \u001b[43mtest_mixing_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_q_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m test_output_mix\u001b[38;5;241m.\u001b[39mshape\n","File \u001b[1;32mc:\\Users\\natsu\\.conda\\envs\\magent2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\natsu\\.conda\\envs\\magent2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mMixingNetwork.forward\u001b[1;34m(self, q_values, state)\u001b[0m\n\u001b[0;32m     14\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(state))\n\u001b[0;32m     15\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreshape(state\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m state_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Concatenate state features with Q-values\u001b[39;00m\n\u001b[0;32m     19\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((state_features, q_values), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\natsu\\.conda\\envs\\magent2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\natsu\\.conda\\envs\\magent2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[1;32mc:\\Users\\natsu\\.conda\\envs\\magent2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x129600 and 10816x128)"]}],"source":["test_state = torch.randn(1, 45, 45, 5)\n","test_q_values = torch.randn(81,21).argmax(dim=1).reshape(1, 81)\n","test_mixing_model = MixingNetwork(81, config[\"obs_shape\"])\n","test_output_mix = test_mixing_model(test_q_values, test_state)\n","test_output_mix.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.914389Z","iopub.status.busy":"2024-12-21T12:21:48.914109Z","iopub.status.idle":"2024-12-21T12:21:48.932367Z","shell.execute_reply":"2024-12-21T12:21:48.931602Z","shell.execute_reply.started":"2024-12-21T12:21:48.914368Z"},"trusted":true},"outputs":[],"source":["class SumTree:\n","    def __init__(self, capacity):\n","        self.capacity = capacity  # Number of leaf nodes (maximum buffer size)\n","        self.tree = np.zeros(2 * capacity - 1)  # Tree structure to store priorities\n","        self.data = np.zeros(capacity, dtype=object)  # Circular buffer for data\n","        self.write = 0  # Pointer to the next data entry\n","\n","    def _propagate(self, idx, change):\n","        parent = (idx - 1) // 2\n","        self.tree[parent] += change\n","\n","        if parent != 0:\n","            self._propagate(parent, change)\n","\n","    def _retrieve(self, idx, s):\n","        left = 2 * idx + 1\n","        right = left + 1\n","\n","        if left >= len(self.tree):  # If we reach a leaf node\n","            return idx\n","\n","        if s <= self.tree[left]:\n","            return self._retrieve(left, s)\n","        else:\n","            return self._retrieve(right, s - self.tree[left])\n","\n","    def total(self):\n","        return self.tree[0]\n","\n","    def add(self, priority, data):\n","        idx = self.write + self.capacity - 1\n","        self.data[self.write] = data\n","        self.update(idx, priority)\n","\n","        self.write += 1\n","        if self.write >= self.capacity:\n","            self.write = 0\n","\n","    def update(self, idx, priority):\n","        change = priority - self.tree[idx]\n","        self.tree[idx] = priority\n","        self._propagate(idx, change)\n","\n","    def get(self, s):\n","        idx = self._retrieve(0, s)\n","        data_idx = idx - self.capacity + 1\n","\n","        return idx, self.tree[idx], self.data[data_idx]\n","\n","    def size(self):\n","        \"\"\"Returns the current size of the buffer.\"\"\"\n","        if self.write < self.capacity:\n","            return self.write  # If the buffer isn't full yet\n","        else:\n","            return self.capacity  # Buffer is full when write pointer has wrapped around"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.934853Z","iopub.status.busy":"2024-12-21T12:21:48.934636Z","iopub.status.idle":"2024-12-21T12:21:48.954195Z","shell.execute_reply":"2024-12-21T12:21:48.953592Z","shell.execute_reply.started":"2024-12-21T12:21:48.934835Z"},"trusted":true},"outputs":[],"source":["class PrioritizedReplayBuffer:\n","    def __init__(self, capacity, alpha):\n","        self.tree = SumTree(capacity)\n","        self.alpha = alpha  # Controls how much prioritization is used (0 - no prioritization)\n","        self.capacity = capacity\n","\n","    def add(self, state, action, reward, next_state, done, global_state, next_global_state, error):\n","        priority = (abs(error) + 1e-5) ** self.alpha\n","        self.tree.add(priority, (state, action, reward, next_state, done, global_state, next_global_state))\n","\n","    def sample(self, batch_size, beta):\n","        batch = []\n","        idxs = []\n","        priorities = []\n","        segment = self.tree.total() / batch_size\n","\n","        for i in range(batch_size):\n","            s = random.uniform(segment * i, segment * (i + 1))\n","            idx, priority, data = self.tree.get(s)\n","            batch.append(data)\n","            idxs.append(idx)\n","            priorities.append(priority)\n","\n","        sampling_probs = priorities / self.tree.total()\n","        weights = (len(self) * sampling_probs) ** -beta\n","        weights /= weights.max()\n","\n","        states, actions, rewards, next_states, dones, global_states, next_global_states = zip(*batch)\n","\n","        return (\n","            idxs,\n","            torch.cat(states).to('cuda'),\n","            torch.tensor(actions, dtype=torch.long).unsqueeze(1).to('cuda'),\n","            torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to('cuda'),\n","            torch.cat(next_states).to('cuda'),\n","            torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to('cuda'),\n","            torch.cat(global_states).to('cuda'),\n","            torch.cat(next_global_states).to('cuda'),\n","            torch.tensor(weights, dtype=torch.float32).unsqueeze(1).to('cuda')\n","        )\n","\n","    def update(self, idxs, errors):\n","        for idx, error in zip(idxs, errors):\n","            priority = (abs(error) + 1e-5) ** self.alpha\n","            self.tree.update(idx, priority)\n","\n","    def __len__(self):\n","        # Assuming the SumTree class has a `size` attribute or equivalent method\n","        return self.tree.size()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.955357Z","iopub.status.busy":"2024-12-21T12:21:48.955161Z","iopub.status.idle":"2024-12-21T12:21:48.975324Z","shell.execute_reply":"2024-12-21T12:21:48.974426Z","shell.execute_reply.started":"2024-12-21T12:21:48.955341Z"},"trusted":true},"outputs":[],"source":["def update_network(network, target_network):\n","  target_network.load_state_dict(network.state_dict())"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:48.976418Z","iopub.status.busy":"2024-12-21T12:21:48.976181Z","iopub.status.idle":"2024-12-21T12:21:49.032246Z","shell.execute_reply":"2024-12-21T12:21:49.031379Z","shell.execute_reply.started":"2024-12-21T12:21:48.976399Z"},"trusted":true},"outputs":[{"data":{"text/plain":["QNetwork(\n","  (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=10816, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=21, bias=True)\n",")"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["blue_q_network = QNetwork(\n","    obs_shape=config[\"obs_shape\"],\n","    actions_dim=config[\"action_dims\"]\n",").to(config[\"device\"])\n","\n","blue_target_q_network = QNetwork(\n","    obs_shape=config[\"obs_shape\"],\n","    actions_dim=config[\"action_dims\"]\n",").to(config[\"device\"])\n","\n","blue_buffer = PrioritizedReplayBuffer(capacity=config[\"buffer_size\"], alpha=config[\"buffer_alpha\"])\n","\n","update_network(blue_q_network, blue_target_q_network)\n","blue_target_q_network.eval()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:49.033428Z","iopub.status.busy":"2024-12-21T12:21:49.033140Z","iopub.status.idle":"2024-12-21T12:21:49.061555Z","shell.execute_reply":"2024-12-21T12:21:49.060714Z","shell.execute_reply.started":"2024-12-21T12:21:49.033395Z"},"trusted":true},"outputs":[{"data":{"text/plain":["QNetwork(\n","  (conv1): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=10816, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=21, bias=True)\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["red_q_network = QNetwork(\n","    obs_shape=config[\"obs_shape\"],\n","    actions_dim=config[\"action_dims\"]\n",").to(config[\"device\"])\n","\n","red_target_q_network = QNetwork(\n","    obs_shape=config[\"obs_shape\"],\n","    actions_dim=config[\"action_dims\"]\n",").to(config[\"device\"])\n","\n","red_buffer = PrioritizedReplayBuffer(capacity=config[\"buffer_size\"], alpha=config[\"buffer_alpha\"])\n","\n","update_network(red_q_network, red_target_q_network)\n","red_target_q_network.eval()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:49.062690Z","iopub.status.busy":"2024-12-21T12:21:49.062361Z","iopub.status.idle":"2024-12-21T12:21:49.384578Z","shell.execute_reply":"2024-12-21T12:21:49.383615Z","shell.execute_reply.started":"2024-12-21T12:21:49.062660Z"},"trusted":true},"outputs":[],"source":["red_mixing_network = MixingNetwork(num_agents=3, state_shape=(45, 45, 5)).to(config[\"device\"])\n","blue_mixing_network = MixingNetwork(num_agents=3, state_shape=(45, 45, 5)).to(config[\"device\"])\n","\n","red_optimizer = optim.Adam(red_q_network.parameters(), lr=config[\"learning_rate\"])\n","blue_optimizer = optim.Adam(blue_q_network.parameters(), lr=config[\"learning_rate\"])\n","red_mixing_optimizer = optim.Adam(red_mixing_network.parameters(), lr=config[\"learning_rate\"])\n","blue_mixing_optimizer = optim.Adam(blue_mixing_network.parameters(), lr=config[\"learning_rate\"])"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T12:21:49.385918Z","iopub.status.busy":"2024-12-21T12:21:49.385593Z","iopub.status.idle":"2024-12-21T12:21:50.269571Z","shell.execute_reply":"2024-12-21T12:21:50.268326Z","shell.execute_reply.started":"2024-12-21T12:21:49.385887Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Q-Mix:   0%|          | 0/50 [00:00<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (218x129 and 131x1)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-9ecf9f0dbb0f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Use the mixing network to compute the joint Q-value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mjoint_q_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mred_mixing_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mtd_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_q_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_q_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-0a359492f8a7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q_values, state)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Concatenate state features with Q-values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (218x129 and 131x1)"]}],"source":["pbar = tqdm(range(config[\"num_episode\"]), desc=\"Training Q-Mix\")\n","beta = config[\"beta\"]\n","\n","for episode in pbar:\n","    obs = env.reset()\n","    obs = obs[0] if isinstance(obs, tuple) else obs\n","    red_total_reward = 0\n","    blue_total_reward = 0\n","    blue_losses = []\n","    red_losses = []\n","\n","    done_agents = set()\n","    beta = min(1.0, beta + config[\"beta_increment\"])\n","\n","    for step in range(config[\"num_step\"]):\n","        actions = {}\n","        red_team = [agent for agent in env.agents if \"red\" in agent and agent not in done_agents]\n","        blue_team = [agent for agent in env.agents if \"blue\" in agent and agent not in done_agents]\n","\n","        # Get the current global state\n","        global_state = torch.tensor(env.state(), dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","\n","        if len(red_team) > 0:\n","            red_team_state = torch.stack(\n","                [torch.tensor(obs[agent], dtype=torch.float32) for agent in red_team]\n","            ).to(config[\"device\"])\n","\n","            with torch.no_grad():\n","                red_q_values = red_q_network(red_team_state)\n","                network_actions = torch.argmax(red_q_values, dim=1)\n","\n","            random_actions = torch.randint(0, config[\"action_dims\"], (len(red_team),), device=config[\"device\"])\n","\n","            red_actions = torch.where(\n","                torch.rand(len(red_team), device=config[\"device\"]) < config[\"epsilon\"],\n","                random_actions,\n","                network_actions\n","            ).to(config[\"device\"])\n","\n","            actions.update({agent: action.item() for agent, action in zip(red_team, red_actions)})\n","\n","        if len(blue_team) > 0:\n","            blue_team_state = torch.stack(\n","                [torch.tensor(obs[agent], dtype=torch.float32) for agent in blue_team]\n","            ).to(config[\"device\"])\n","\n","            with torch.no_grad():\n","                blue_q_values = blue_q_network(blue_team_state)\n","                network_actions = torch.argmax(blue_q_values, dim=1)\n","\n","            random_actions = torch.randint(0, config[\"action_dims\"], (len(blue_team),), device=config[\"device\"])\n","\n","            blue_actions = torch.where(\n","                torch.rand(len(blue_team), device=config[\"device\"]) < config[\"epsilon\"],\n","                random_actions,\n","                network_actions\n","            ).to(config[\"device\"])\n","\n","            actions.update({agent: action.item() for agent, action in zip(blue_team, blue_actions)})\n","\n","        next_obs, rewards, terminations, truncations, infos = env.step(actions)\n","        dones = {agent: terminations.get(agent, False) or truncations.get(agent, False) for agent in env.agents}\n","\n","        # Get the next global state\n","        next_global_state = torch.tensor(env.state(), dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","\n","        for agent in red_team:\n","            if agent in done_agents:\n","                continue\n","            state = torch.tensor(obs[agent], dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","            action = actions[agent]\n","            reward = rewards.get(agent, 0.0)\n","            next_state = torch.tensor(next_obs[agent], dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","            done = dones.get(agent, False)\n","\n","            error = 1.0\n","            red_buffer.add(state, action, reward, next_state, done, global_state, next_global_state, error)\n","            red_total_reward += reward\n","\n","            if done:\n","                done_agents.add(agent)\n","\n","        for agent in blue_team:\n","            if agent in done_agents:\n","                continue\n","            state = torch.tensor(obs[agent], dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","            action = actions[agent]\n","            reward = rewards.get(agent, 0.0)\n","            next_state = torch.tensor(next_obs[agent], dtype=torch.float32).unsqueeze(0).to(config[\"device\"])\n","            done = dones.get(agent, False)\n","\n","            error = 1.0\n","            blue_buffer.add(state, action, reward, next_state, done, global_state, next_global_state, error)\n","            blue_total_reward += reward\n","\n","            if done:\n","                done_agents.add(agent)\n","\n","        obs = next_obs\n","\n","        if len(red_buffer) >= config[\"batch_size\"]:\n","            idxs, states, actions, rewards, next_states, dones, global_states, next_global_states, weights = red_buffer.sample(config[\"batch_size\"], beta)\n","\n","            q_values = red_q_network(states).gather(1, actions)\n","            with torch.no_grad():\n","                next_actions = red_q_network(next_states).argmax(1, keepdim=True)\n","                next_q_values = red_target_q_network(next_states).gather(1, next_actions)\n","                target_q_values = rewards + (1 - dones) * config[\"gamma\"] * next_q_values\n","\n","            # Use the mixing network to compute the joint Q-value\n","            joint_q_value = red_mixing_network(q_values, global_states)\n","\n","            td_errors = torch.abs(joint_q_value - target_q_values).detach().cpu().numpy()\n","            red_buffer.update(idxs, td_errors)\n","\n","            loss = (torch.tensor(weights, dtype=torch.float32, device=config[\"device\"]).squeeze() * F.mse_loss(joint_q_value, target_q_values, reduction=\"none\").squeeze()).mean()\n","            red_losses.append(loss.item())\n","            red_optimizer.zero_grad()\n","            loss.backward()\n","            red_optimizer.step()\n","\n","            # Update the mixing network\n","            red_mixing_optimizer.zero_grad()\n","            loss.backward()\n","            red_mixing_optimizer.step()\n","\n","        if len(blue_buffer) >= config[\"batch_size\"]:\n","            idxs, states, actions, rewards, next_states, dones, global_states, next_global_states, weights = blue_buffer.sample(config[\"batch_size\"], beta)\n","\n","            q_values = blue_q_network(states).gather(1, actions)\n","            with torch.no_grad():\n","                next_actions = blue_q_network(next_states).argmax(1, keepdim=True)\n","                next_q_values = blue_target_q_network(next_states).gather(1, next_actions)\n","                target_q_values = rewards + (1 - dones) * config[\"gamma\"] * next_q_values\n","\n","            # Use the mixing network to compute the joint Q-value\n","            joint_q_value = blue_mixing_network(q_values, global_states)\n","\n","            td_errors = torch.abs(joint_q_value - target_q_values).detach().cpu().numpy()\n","            blue_buffer.update(idxs, td_errors)\n","\n","            loss = (torch.tensor(weights, dtype=torch.float32, device=config[\"device\"]).squeeze() * F.mse_loss(joint_q_value, target_q_values, reduction=\"none\").squeeze()).mean()\n","            blue_losses.append(loss.item())\n","            blue_optimizer.zero_grad()\n","            loss.backward()\n","            blue_optimizer.step()\n","\n","            # Update the mixing network\n","            blue_mixing_optimizer.zero_grad()\n","            loss.backward()\n","            blue_mixing_optimizer.step()\n","\n","    pbar.set_postfix({\n","        'Red Reward': red_total_reward,\n","        'Red Loss': red_losses[-1] if red_losses else 0,\n","        'Blue Reward': blue_total_reward,\n","        'Blue Loss': blue_losses[-1] if blue_losses else 0,\n","        'Epsilon': config['epsilon']\n","    })\n","\n","    if config[\"epsilon\"] > config[\"epsilon_min\"]:\n","        config[\"epsilon\"] *= config[\"epsilon_decay\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-12-21T12:21:50.270128Z","iopub.status.idle":"2024-12-21T12:21:50.270407Z","shell.execute_reply":"2024-12-21T12:21:50.270292Z"},"trusted":true},"outputs":[],"source":["torch.save(blue_q_network.state_dict(), \"blue_qmix.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-12-21T12:21:50.271435Z","iopub.status.idle":"2024-12-21T12:21:50.271721Z","shell.execute_reply":"2024-12-21T12:21:50.271611Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Load the loss data\n","\n","# Create the plot\n","plt.figure(figsize=(10, 5))  # Adjust figure size if needed\n","plt.plot(red_losses, label=\"Red Agent Loss\", color=\"red\")\n","plt.plot(blue_losses, label=\"Blue Agent Loss\", color=\"blue\")\n","plt.title(\"Training Loss for Red and Blue Agents\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.grid(True)  # Add a grid for better visualization\n","\n","# Display the plot\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
